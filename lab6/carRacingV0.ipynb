{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install SWIG https://sourceforge.net/projects/swig/files/swigwin/swigwin-4.0.2/swigwin-4.0.2.zip/download?use_mirror=ixpeering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gym[box2d] pyglet==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "from stable_baselines3 import PPO, SAC\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"CarRacing-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1204..1509 -> 305-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Po ustawieniu trybu wątku nie można go zmienić\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-34.210526315789956\n",
      "Track generation: 1174..1472 -> 298-tiles track\n",
      "Episode:2 Score:-32.659932659933084\n"
     ]
    }
   ],
   "source": [
    "episodes = 2\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09588507,  0.37376758,  0.03940687], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[252,  73,  97],\n",
       "        [ 69, 177,   9],\n",
       "        [124,  77, 119],\n",
       "        ...,\n",
       "        [203, 132,   9],\n",
       "        [ 58, 103,  43],\n",
       "        [237,  65, 173]],\n",
       "\n",
       "       [[ 58, 204, 190],\n",
       "        [126, 238, 145],\n",
       "        [252, 221,  34],\n",
       "        ...,\n",
       "        [153,  28, 101],\n",
       "        [ 48,  31, 195],\n",
       "        [141, 198, 137]],\n",
       "\n",
       "       [[ 11,  72,  43],\n",
       "        [158, 205, 224],\n",
       "        [ 91,  45,  63],\n",
       "        ...,\n",
       "        [179,  85,  17],\n",
       "        [123, 132, 106],\n",
       "        [ 48,  76, 122]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[156,  75, 135],\n",
       "        [ 42, 127,  18],\n",
       "        [221,  19, 126],\n",
       "        ...,\n",
       "        [245, 205,  57],\n",
       "        [ 45, 191,  96],\n",
       "        [136, 230,  87]],\n",
       "\n",
       "       [[195, 171, 215],\n",
       "        [204, 254,   6],\n",
       "        [140,  12,  53],\n",
       "        ...,\n",
       "        [200,  92, 186],\n",
       "        [ 60, 180,  67],\n",
       "        [190, 180,  68]],\n",
       "\n",
       "       [[183, 109, 190],\n",
       "        [238,  29, 208],\n",
       "        [238, 188,  12],\n",
       "        ...,\n",
       "        [ 99, 237,  48],\n",
       "        [152,  31, 177],\n",
       "        [ 38, 111, 119]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Adding a callback to the training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnNoModelImprovement(\n",
    "    max_no_improvement_evals=10, min_evals=20, verbose=True)\n",
    "eval_callback = EvalCallback(env,\n",
    "                             callback_on_new_best=stop_callback,\n",
    "                             eval_freq=10000,\n",
    "                             best_model_save_path=save_path,\n",
    "                             verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 25.7 GiB for an array with shape (1000000, 1, 3, 96, 96) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5016\\3414065035.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0menv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDummyVecEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSAC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CnnPolicy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard_log\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\stable_baselines3\\sac\\sac.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, ent_coef, target_update_interval, target_entropy, use_sde, sde_sample_freq, use_sde_at_warmup, tensorboard_log, create_eval_env, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_init_setup_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setup_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\stable_baselines3\\sac\\sac.py\u001b[0m in \u001b[0;36m_setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setup_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSAC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_aliases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;31m# Target entropy is used when learning the entropy coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py\u001b[0m in \u001b[0;36m_setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             self.replay_buffer = self.replay_buffer_class(\n\u001b[0m\u001b[0;32m    207\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\stable_baselines3\\common\\buffers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, buffer_size, observation_space, action_space, device, n_envs, optimize_memory_usage, handle_timeout_termination)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_memory_usage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize_memory_usage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_envs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moptimize_memory_usage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 25.7 GiB for an array with shape (1000000, 1, 3, 96, 96) and data type uint8"
     ]
    }
   ],
   "source": [
    "env2 = DummyVecEnv([lambda: env])\n",
    "model = SAC(\"CnnPolicy\", env2, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1231..1542 -> 311-tiles track\n",
      "Logging to Training\\Logs\\SAC_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:345: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x00000252D6470A30> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x00000252B806E2C0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1242..1557 -> 315-tiles track\n",
      "Track generation: 1096..1381 -> 285-tiles track\n",
      "Track generation: 1110..1400 -> 290-tiles track\n",
      "Track generation: 1156..1449 -> 293-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 1064     |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.93    |\n",
      "|    critic_loss     | 0.738    |\n",
      "|    ent_coef        | 0.311    |\n",
      "|    ent_coef_loss   | -5.86    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3899     |\n",
      "---------------------------------\n",
      "Track generation: 1093..1378 -> 285-tiles track\n",
      "Track generation: 980..1229 -> 249-tiles track\n",
      "Track generation: 1072..1344 -> 272-tiles track\n",
      "Track generation: 1399..1753 -> 354-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 2153     |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.99    |\n",
      "|    critic_loss     | 0.504    |\n",
      "|    ent_coef        | 0.0936   |\n",
      "|    ent_coef_loss   | -11.9    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7899     |\n",
      "---------------------------------\n",
      "Track generation: 1149..1440 -> 291-tiles track\n",
      "Track generation: 1214..1521 -> 307-tiles track\n",
      "Track generation: 1368..1714 -> 346-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 960..1208 -> 248-tiles track\n",
      "Track generation: 979..1231 -> 252-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1181..1481 -> 300-tiles track\n",
      "Track generation: 1263..1583 -> 320-tiles track\n",
      "Track generation: 1122..1406 -> 284-tiles track\n",
      "Track generation: 1177..1477 -> 300-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1109..1390 -> 281-tiles track\n",
      "Eval num_timesteps=10000, episode_reward=-21.38 +/- 23.71\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -21.4    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.56    |\n",
      "|    critic_loss     | 0.767    |\n",
      "|    ent_coef        | 0.0514   |\n",
      "|    ent_coef_loss   | -15      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9899     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Track generation: 1200..1504 -> 304-tiles track\n",
      "Track generation: 1198..1501 -> 303-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 3259     |\n",
      "|    total_timesteps | 12000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.07    |\n",
      "|    critic_loss     | 0.311    |\n",
      "|    ent_coef        | 0.0282   |\n",
      "|    ent_coef_loss   | -17.8    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 11899    |\n",
      "---------------------------------\n",
      "Track generation: 1233..1545 -> 312-tiles track\n",
      "Track generation: 1095..1377 -> 282-tiles track\n",
      "Track generation: 1159..1453 -> 294-tiles track\n",
      "Track generation: 1436..1799 -> 363-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 4349     |\n",
      "|    total_timesteps | 16000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.78    |\n",
      "|    critic_loss     | 0.014    |\n",
      "|    ent_coef        | 0.00991  |\n",
      "|    ent_coef_loss   | -14.6    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15899    |\n",
      "---------------------------------\n",
      "Track generation: 1076..1349 -> 273-tiles track\n",
      "Track generation: 1047..1313 -> 266-tiles track\n",
      "Track generation: 1163..1458 -> 295-tiles track\n",
      "Track generation: 1223..1533 -> 310-tiles track\n",
      "Track generation: 1168..1464 -> 296-tiles track\n",
      "Track generation: 1218..1527 -> 309-tiles track\n",
      "Track generation: 1163..1458 -> 295-tiles track\n",
      "Track generation: 1317..1650 -> 333-tiles track\n",
      "Track generation: 1121..1405 -> 284-tiles track\n",
      "Track generation: 1042..1309 -> 267-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1223..1533 -> 310-tiles track\n",
      "Eval num_timesteps=20000, episode_reward=-73.47 +/- 1.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -73.5    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 20000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.61    |\n",
      "|    critic_loss     | 0.28     |\n",
      "|    ent_coef        | 0.00296  |\n",
      "|    ent_coef_loss   | -15.6    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19899    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    episodes        | 20    |\n",
      "|    fps             | 3     |\n",
      "|    time_elapsed    | 5457  |\n",
      "|    total_timesteps | 20000 |\n",
      "------------------------------\n",
      "Track generation: 1128..1414 -> 286-tiles track\n",
      "Track generation: 1187..1488 -> 301-tiles track\n",
      "Track generation: 1091..1368 -> 277-tiles track\n",
      "Track generation: 1057..1325 -> 268-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 6547     |\n",
      "|    total_timesteps | 24000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.2    |\n",
      "|    critic_loss     | 0.612    |\n",
      "|    ent_coef        | 0.00283  |\n",
      "|    ent_coef_loss   | 39.2     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 23899    |\n",
      "---------------------------------\n",
      "Track generation: 1263..1581 -> 318-tiles track\n",
      "Track generation: 1086..1371 -> 285-tiles track\n",
      "Track generation: 1073..1345 -> 272-tiles track\n",
      "Track generation: 1130..1416 -> 286-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 7638     |\n",
      "|    total_timesteps | 28000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.79    |\n",
      "|    critic_loss     | 0.274    |\n",
      "|    ent_coef        | 0.00252  |\n",
      "|    ent_coef_loss   | -15.3    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 27899    |\n",
      "---------------------------------\n",
      "Track generation: 1057..1329 -> 272-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1271..1601 -> 330-tiles track\n",
      "Track generation: 972..1224 -> 252-tiles track\n",
      "Track generation: 1247..1563 -> 316-tiles track\n",
      "Track generation: 1257..1575 -> 318-tiles track\n",
      "Track generation: 1108..1389 -> 281-tiles track\n",
      "Track generation: 930..1167 -> 237-tiles track\n",
      "Track generation: 907..1145 -> 238-tiles track\n",
      "Track generation: 1283..1608 -> 325-tiles track\n",
      "Eval num_timesteps=30000, episode_reward=-81.64 +/- 2.39\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -81.6    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 30000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.18    |\n",
      "|    critic_loss     | 0.273    |\n",
      "|    ent_coef        | 0.00181  |\n",
      "|    ent_coef_loss   | -9.74    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 29899    |\n",
      "---------------------------------\n",
      "Track generation: 1098..1376 -> 278-tiles track\n",
      "Track generation: 1162..1456 -> 294-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 8746     |\n",
      "|    total_timesteps | 32000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.18    |\n",
      "|    critic_loss     | 0.196    |\n",
      "|    ent_coef        | 0.00146  |\n",
      "|    ent_coef_loss   | -4.44    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 31899    |\n",
      "---------------------------------\n",
      "Track generation: 1077..1358 -> 281-tiles track\n",
      "Track generation: 1217..1526 -> 309-tiles track\n",
      "Track generation: 1216..1524 -> 308-tiles track\n",
      "Track generation: 1074..1345 -> 271-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 9838     |\n",
      "|    total_timesteps | 36000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2       |\n",
      "|    critic_loss     | 0.419    |\n",
      "|    ent_coef        | 0.000603 |\n",
      "|    ent_coef_loss   | -5.26    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 35899    |\n",
      "---------------------------------\n",
      "Track generation: 1147..1438 -> 291-tiles track\n",
      "Track generation: 1071..1347 -> 276-tiles track\n",
      "Track generation: 1112..1394 -> 282-tiles track\n",
      "Track generation: 1104..1393 -> 289-tiles track\n",
      "Track generation: 1300..1629 -> 329-tiles track\n",
      "Track generation: 1135..1423 -> 288-tiles track\n",
      "Track generation: 1135..1423 -> 288-tiles track\n",
      "Track generation: 1128..1415 -> 287-tiles track\n",
      "Track generation: 1048..1316 -> 268-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1129..1418 -> 289-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1064..1334 -> 270-tiles track\n",
      "Track generation: 1228..1539 -> 311-tiles track\n",
      "Eval num_timesteps=40000, episode_reward=-71.73 +/- 2.36\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -71.7    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 40000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.13    |\n",
      "|    critic_loss     | 0.297    |\n",
      "|    ent_coef        | 0.00133  |\n",
      "|    ent_coef_loss   | -0.423   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 39899    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    episodes        | 40    |\n",
      "|    fps             | 3     |\n",
      "|    time_elapsed    | 10945 |\n",
      "|    total_timesteps | 40000 |\n",
      "------------------------------\n",
      "Track generation: 1124..1409 -> 285-tiles track\n",
      "Track generation: 1220..1529 -> 309-tiles track\n",
      "Track generation: 1195..1498 -> 303-tiles track\n",
      "Track generation: 1224..1534 -> 310-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 12035    |\n",
      "|    total_timesteps | 44000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.336   |\n",
      "|    critic_loss     | 0.258    |\n",
      "|    ent_coef        | 0.00172  |\n",
      "|    ent_coef_loss   | 10.6     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 43899    |\n",
      "---------------------------------\n",
      "Track generation: 1180..1479 -> 299-tiles track\n",
      "Track generation: 1078..1359 -> 281-tiles track\n",
      "Track generation: 1060..1336 -> 276-tiles track\n",
      "Track generation: 1120..1403 -> 283-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 13125    |\n",
      "|    total_timesteps | 48000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.69    |\n",
      "|    critic_loss     | 0.189    |\n",
      "|    ent_coef        | 0.00172  |\n",
      "|    ent_coef_loss   | -7.66    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 47899    |\n",
      "---------------------------------\n",
      "Track generation: 1271..1593 -> 322-tiles track\n",
      "Track generation: 1084..1359 -> 275-tiles track\n",
      "Track generation: 994..1246 -> 252-tiles track\n",
      "Track generation: 1267..1589 -> 322-tiles track\n",
      "Track generation: 1238..1552 -> 314-tiles track\n",
      "Track generation: 1259..1578 -> 319-tiles track\n",
      "Track generation: 1256..1574 -> 318-tiles track\n",
      "Track generation: 1109..1399 -> 290-tiles track\n",
      "Eval num_timesteps=50000, episode_reward=-80.09 +/- 2.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -80.1    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 50000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.22    |\n",
      "|    critic_loss     | 0.322    |\n",
      "|    ent_coef        | 0.000959 |\n",
      "|    ent_coef_loss   | -23.8    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 49899    |\n",
      "---------------------------------\n",
      "Track generation: 1180..1479 -> 299-tiles track\n",
      "Track generation: 1168..1464 -> 296-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 14233    |\n",
      "|    total_timesteps | 52000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.48    |\n",
      "|    critic_loss     | 0.821    |\n",
      "|    ent_coef        | 0.00115  |\n",
      "|    ent_coef_loss   | 4.63     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 51899    |\n",
      "---------------------------------\n",
      "Track generation: 1059..1327 -> 268-tiles track\n",
      "Track generation: 1141..1438 -> 297-tiles track\n",
      "Track generation: 1130..1417 -> 287-tiles track\n",
      "Track generation: 1089..1365 -> 276-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 15324    |\n",
      "|    total_timesteps | 56000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.01    |\n",
      "|    critic_loss     | 0.306    |\n",
      "|    ent_coef        | 0.00102  |\n",
      "|    ent_coef_loss   | -28.8    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 55899    |\n",
      "---------------------------------\n",
      "Track generation: 1069..1340 -> 271-tiles track\n",
      "Track generation: 1079..1359 -> 280-tiles track\n",
      "Track generation: 1174..1472 -> 298-tiles track\n",
      "Track generation: 1121..1405 -> 284-tiles track\n",
      "Track generation: 1085..1369 -> 284-tiles track\n",
      "Track generation: 1103..1383 -> 280-tiles track\n",
      "Track generation: 1151..1443 -> 292-tiles track\n",
      "Track generation: 1267..1588 -> 321-tiles track\n",
      "Track generation: 1257..1575 -> 318-tiles track\n",
      "Track generation: 1244..1559 -> 315-tiles track\n",
      "Eval num_timesteps=60000, episode_reward=-83.17 +/- 0.96\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -83.2    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 60000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.402   |\n",
      "|    critic_loss     | 0.0588   |\n",
      "|    ent_coef        | 0.000666 |\n",
      "|    ent_coef_loss   | -10.1    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 59899    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    episodes        | 60    |\n",
      "|    fps             | 3     |\n",
      "|    time_elapsed    | 16434 |\n",
      "|    total_timesteps | 60000 |\n",
      "------------------------------\n",
      "Track generation: 1159..1453 -> 294-tiles track\n",
      "Track generation: 1224..1534 -> 310-tiles track\n",
      "Track generation: 1206..1512 -> 306-tiles track\n",
      "Track generation: 1019..1284 -> 265-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 17529    |\n",
      "|    total_timesteps | 64000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.143    |\n",
      "|    critic_loss     | 0.228    |\n",
      "|    ent_coef        | 0.000653 |\n",
      "|    ent_coef_loss   | -21.4    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 63899    |\n",
      "---------------------------------\n",
      "Track generation: 1202..1510 -> 308-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1202..1515 -> 313-tiles track\n",
      "Track generation: 1167..1463 -> 296-tiles track\n",
      "Track generation: 1193..1495 -> 302-tiles track\n",
      "Track generation: 1006..1269 -> 263-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 18627    |\n",
      "|    total_timesteps | 68000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.763    |\n",
      "|    critic_loss     | 0.129    |\n",
      "|    ent_coef        | 0.000737 |\n",
      "|    ent_coef_loss   | -3.14    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 67899    |\n",
      "---------------------------------\n",
      "Track generation: 1198..1501 -> 303-tiles track\n",
      "Track generation: 1052..1326 -> 274-tiles track\n",
      "Track generation: 1154..1454 -> 300-tiles track\n",
      "Track generation: 1206..1512 -> 306-tiles track\n",
      "Track generation: 1089..1365 -> 276-tiles track\n",
      "Track generation: 1028..1289 -> 261-tiles track\n",
      "Track generation: 1050..1322 -> 272-tiles track\n",
      "Track generation: 1220..1529 -> 309-tiles track\n",
      "Eval num_timesteps=70000, episode_reward=-92.88 +/- 0.43\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -92.9    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 70000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.19    |\n",
      "|    critic_loss     | 7.25     |\n",
      "|    ent_coef        | 0.000857 |\n",
      "|    ent_coef_loss   | 68.4     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 69899    |\n",
      "---------------------------------\n",
      "Track generation: 1115..1401 -> 286-tiles track\n",
      "Track generation: 1075..1348 -> 273-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 19745    |\n",
      "|    total_timesteps | 72000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.39    |\n",
      "|    critic_loss     | 0.61     |\n",
      "|    ent_coef        | 0.00132  |\n",
      "|    ent_coef_loss   | 19.2     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 71899    |\n",
      "---------------------------------\n",
      "Track generation: 1232..1544 -> 312-tiles track\n",
      "Track generation: 1300..1630 -> 330-tiles track\n",
      "Track generation: 1128..1414 -> 286-tiles track\n",
      "Track generation: 1047..1313 -> 266-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 20842    |\n",
      "|    total_timesteps | 76000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.703    |\n",
      "|    critic_loss     | 2.54     |\n",
      "|    ent_coef        | 0.0019   |\n",
      "|    ent_coef_loss   | -26      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 75899    |\n",
      "---------------------------------\n",
      "Track generation: 1159..1460 -> 301-tiles track\n",
      "Track generation: 1064..1334 -> 270-tiles track\n",
      "Track generation: 1172..1469 -> 297-tiles track\n",
      "Track generation: 1322..1656 -> 334-tiles track\n",
      "Track generation: 1108..1389 -> 281-tiles track\n",
      "Track generation: 1015..1271 -> 256-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1164..1459 -> 295-tiles track\n",
      "Track generation: 1175..1474 -> 299-tiles track\n",
      "Track generation: 1176..1474 -> 298-tiles track\n",
      "Track generation: 1127..1413 -> 286-tiles track\n",
      "Track generation: 1168..1464 -> 296-tiles track\n",
      "Eval num_timesteps=80000, episode_reward=-82.80 +/- 0.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -82.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 80000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.44    |\n",
      "|    critic_loss     | 0.149    |\n",
      "|    ent_coef        | 0.00144  |\n",
      "|    ent_coef_loss   | -15.5    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 79899    |\n",
      "---------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    episodes        | 80    |\n",
      "|    fps             | 3     |\n",
      "|    time_elapsed    | 21961 |\n",
      "|    total_timesteps | 80000 |\n",
      "------------------------------\n",
      "Track generation: 1092..1372 -> 280-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1051..1324 -> 273-tiles track\n",
      "Track generation: 1324..1659 -> 335-tiles track\n",
      "Track generation: 1337..1683 -> 346-tiles track\n",
      "Track generation: 1106..1387 -> 281-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 23058    |\n",
      "|    total_timesteps | 84000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.51     |\n",
      "|    critic_loss     | 0.25     |\n",
      "|    ent_coef        | 0.00118  |\n",
      "|    ent_coef_loss   | 18       |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 83899    |\n",
      "---------------------------------\n",
      "Track generation: 1028..1289 -> 261-tiles track\n",
      "Track generation: 1201..1505 -> 304-tiles track\n",
      "Track generation: 1207..1513 -> 306-tiles track\n",
      "Track generation: 1195..1498 -> 303-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 24154    |\n",
      "|    total_timesteps | 88000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0622   |\n",
      "|    critic_loss     | 0.197    |\n",
      "|    ent_coef        | 0.000853 |\n",
      "|    ent_coef_loss   | 0.741    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 87899    |\n",
      "---------------------------------\n",
      "Track generation: 1041..1307 -> 266-tiles track\n",
      "Track generation: 1060..1329 -> 269-tiles track\n",
      "Track generation: 1061..1332 -> 271-tiles track\n",
      "Track generation: 1116..1399 -> 283-tiles track\n",
      "Track generation: 985..1239 -> 254-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1148..1446 -> 298-tiles track\n",
      "Track generation: 1249..1565 -> 316-tiles track\n",
      "Track generation: 1270..1590 -> 320-tiles track\n",
      "Track generation: 1176..1481 -> 305-tiles track\n",
      "Eval num_timesteps=90000, episode_reward=-83.75 +/- 1.76\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -83.7    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 90000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.593    |\n",
      "|    critic_loss     | 0.0567   |\n",
      "|    ent_coef        | 0.000789 |\n",
      "|    ent_coef_loss   | 5.68     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 89899    |\n",
      "---------------------------------\n",
      "Track generation: 1264..1584 -> 320-tiles track\n",
      "Track generation: 1127..1413 -> 286-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 25268    |\n",
      "|    total_timesteps | 92000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.26    |\n",
      "|    critic_loss     | 0.243    |\n",
      "|    ent_coef        | 0.000823 |\n",
      "|    ent_coef_loss   | -7.11    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 91899    |\n",
      "---------------------------------\n",
      "Track generation: 1121..1413 -> 292-tiles track\n",
      "Track generation: 1037..1308 -> 271-tiles track\n",
      "Track generation: 1237..1519 -> 282-tiles track\n",
      "Track generation: 1523..1908 -> 385-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 26367    |\n",
      "|    total_timesteps | 96000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.141    |\n",
      "|    critic_loss     | 0.128    |\n",
      "|    ent_coef        | 0.000467 |\n",
      "|    ent_coef_loss   | -26.1    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 95899    |\n",
      "---------------------------------\n",
      "Track generation: 1140..1429 -> 289-tiles track\n",
      "Track generation: 1083..1358 -> 275-tiles track\n",
      "Track generation: 1221..1530 -> 309-tiles track\n",
      "Track generation: 1256..1575 -> 319-tiles track\n",
      "Track generation: 1061..1330 -> 269-tiles track\n",
      "Track generation: 1271..1593 -> 322-tiles track\n",
      "Track generation: 1199..1502 -> 303-tiles track\n",
      "Track generation: 1047..1313 -> 266-tiles track\n",
      "Track generation: 976..1224 -> 248-tiles track\n",
      "Track generation: 1080..1354 -> 274-tiles track\n",
      "Eval num_timesteps=100000, episode_reward=-82.02 +/- 1.68\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -82      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 100000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.377    |\n",
      "|    critic_loss     | 0.249    |\n",
      "|    ent_coef        | 0.000573 |\n",
      "|    ent_coef_loss   | 21.3     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 99899    |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    episodes        | 100    |\n",
      "|    fps             | 3      |\n",
      "|    time_elapsed    | 27482  |\n",
      "|    total_timesteps | 100000 |\n",
      "-------------------------------\n",
      "Track generation: 1196..1499 -> 303-tiles track\n",
      "Track generation: 1160..1454 -> 294-tiles track\n",
      "Track generation: 1111..1393 -> 282-tiles track\n",
      "Track generation: 1155..1456 -> 301-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 28579    |\n",
      "|    total_timesteps | 104000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.175   |\n",
      "|    critic_loss     | 0.583    |\n",
      "|    ent_coef        | 0.000669 |\n",
      "|    ent_coef_loss   | -13.8    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 103899   |\n",
      "---------------------------------\n",
      "Track generation: 1093..1374 -> 281-tiles track\n",
      "Track generation: 1075..1348 -> 273-tiles track\n",
      "Track generation: 1099..1382 -> 283-tiles track\n",
      "Track generation: 1129..1419 -> 290-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1223..1541 -> 318-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 29543    |\n",
      "|    total_timesteps | 107518   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.339    |\n",
      "|    critic_loss     | 0.00965  |\n",
      "|    ent_coef        | 0.000711 |\n",
      "|    ent_coef_loss   | 30.5     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 107417   |\n",
      "---------------------------------\n",
      "Track generation: 1146..1437 -> 291-tiles track\n",
      "Track generation: 1282..1607 -> 325-tiles track\n",
      "Track generation: 1164..1459 -> 295-tiles track\n",
      "Track generation: 1089..1372 -> 283-tiles track\n",
      "Track generation: 1143..1433 -> 290-tiles track\n",
      "Track generation: 979..1230 -> 251-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1137..1426 -> 289-tiles track\n",
      "Track generation: 1234..1546 -> 312-tiles track\n",
      "Track generation: 1133..1425 -> 292-tiles track\n",
      "Eval num_timesteps=110000, episode_reward=-80.84 +/- 1.92\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -80.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 110000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.32    |\n",
      "|    critic_loss     | 0.433    |\n",
      "|    ent_coef        | 0.000986 |\n",
      "|    ent_coef_loss   | -2.06    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 109899   |\n",
      "---------------------------------\n",
      "Track generation: 1190..1493 -> 303-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1103..1383 -> 280-tiles track\n",
      "Track generation: 1024..1293 -> 269-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 30789    |\n",
      "|    total_timesteps | 112000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.62     |\n",
      "|    critic_loss     | 0.202    |\n",
      "|    ent_coef        | 0.000677 |\n",
      "|    ent_coef_loss   | -7.97    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 111899   |\n",
      "---------------------------------\n",
      "Track generation: 1089..1370 -> 281-tiles track\n",
      "Track generation: 1208..1514 -> 306-tiles track\n",
      "Track generation: 1109..1399 -> 290-tiles track\n",
      "Track generation: 1252..1569 -> 317-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 31887    |\n",
      "|    total_timesteps | 116000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.898   |\n",
      "|    critic_loss     | 0.354    |\n",
      "|    ent_coef        | 0.000717 |\n",
      "|    ent_coef_loss   | 54.3     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 115899   |\n",
      "---------------------------------\n",
      "Track generation: 1139..1435 -> 296-tiles track\n",
      "Track generation: 1262..1591 -> 329-tiles track\n",
      "Track generation: 1165..1460 -> 295-tiles track\n",
      "Track generation: 1300..1629 -> 329-tiles track\n",
      "Track generation: 1180..1479 -> 299-tiles track\n",
      "Track generation: 983..1233 -> 250-tiles track\n",
      "Track generation: 1134..1419 -> 285-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1184..1484 -> 300-tiles track\n",
      "Track generation: 1231..1543 -> 312-tiles track\n",
      "Track generation: 947..1192 -> 245-tiles track\n",
      "Track generation: 1018..1280 -> 262-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1107..1388 -> 281-tiles track\n",
      "Eval num_timesteps=120000, episode_reward=-82.79 +/- 1.46\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -82.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 120000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.852    |\n",
      "|    critic_loss     | 0.00618  |\n",
      "|    ent_coef        | 0.000648 |\n",
      "|    ent_coef_loss   | 6.43     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 119899   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    episodes        | 120    |\n",
      "|    fps             | 3      |\n",
      "|    time_elapsed    | 33005  |\n",
      "|    total_timesteps | 120000 |\n",
      "-------------------------------\n",
      "Track generation: 980..1233 -> 253-tiles track\n",
      "Track generation: 1015..1273 -> 258-tiles track\n",
      "Track generation: 1197..1509 -> 312-tiles track\n",
      "Track generation: 1123..1416 -> 293-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 34102    |\n",
      "|    total_timesteps | 124000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.14     |\n",
      "|    critic_loss     | 0.443    |\n",
      "|    ent_coef        | 0.000627 |\n",
      "|    ent_coef_loss   | 1.51     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 123899   |\n",
      "---------------------------------\n",
      "Track generation: 1116..1399 -> 283-tiles track\n",
      "Track generation: 1207..1513 -> 306-tiles track\n",
      "Track generation: 1171..1468 -> 297-tiles track\n",
      "Track generation: 1228..1539 -> 311-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 35200    |\n",
      "|    total_timesteps | 128000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.15     |\n",
      "|    critic_loss     | 0.0908   |\n",
      "|    ent_coef        | 0.000591 |\n",
      "|    ent_coef_loss   | 9.18     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 127899   |\n",
      "---------------------------------\n",
      "Track generation: 1295..1623 -> 328-tiles track\n",
      "Track generation: 1184..1484 -> 300-tiles track\n",
      "Track generation: 1111..1393 -> 282-tiles track\n",
      "Track generation: 1256..1574 -> 318-tiles track\n",
      "Track generation: 1078..1352 -> 274-tiles track\n",
      "Track generation: 1204..1509 -> 305-tiles track\n",
      "Track generation: 1373..1726 -> 353-tiles track\n",
      "Track generation: 1034..1299 -> 265-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1166..1469 -> 303-tiles track\n",
      "Eval num_timesteps=130000, episode_reward=-84.06 +/- 2.46\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -84.1    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 130000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.874    |\n",
      "|    critic_loss     | 0.114    |\n",
      "|    ent_coef        | 0.000618 |\n",
      "|    ent_coef_loss   | 1.67     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 129899   |\n",
      "---------------------------------\n",
      "Track generation: 1209..1515 -> 306-tiles track\n",
      "Track generation: 1119..1403 -> 284-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 36325    |\n",
      "|    total_timesteps | 132000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.06     |\n",
      "|    critic_loss     | 0.207    |\n",
      "|    ent_coef        | 0.00053  |\n",
      "|    ent_coef_loss   | -19.4    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 131899   |\n",
      "---------------------------------\n",
      "Track generation: 1229..1540 -> 311-tiles track\n",
      "Track generation: 1268..1589 -> 321-tiles track\n",
      "Track generation: 1163..1458 -> 295-tiles track\n",
      "Track generation: 1083..1358 -> 275-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 37429    |\n",
      "|    total_timesteps | 136000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.81     |\n",
      "|    critic_loss     | 0.00107  |\n",
      "|    ent_coef        | 0.000488 |\n",
      "|    ent_coef_loss   | 1.96     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 135899   |\n",
      "---------------------------------\n",
      "Track generation: 1052..1319 -> 267-tiles track\n",
      "Track generation: 1235..1547 -> 312-tiles track\n",
      "Track generation: 1061..1342 -> 281-tiles track\n",
      "Track generation: 971..1222 -> 251-tiles track\n",
      "Track generation: 1152..1444 -> 292-tiles track\n",
      "Track generation: 1136..1424 -> 288-tiles track\n",
      "Track generation: 1089..1374 -> 285-tiles track\n",
      "Track generation: 1014..1271 -> 257-tiles track\n",
      "Track generation: 1090..1375 -> 285-tiles track\n",
      "Track generation: 1128..1414 -> 286-tiles track\n",
      "Eval num_timesteps=140000, episode_reward=-67.84 +/- 1.52\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -67.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 140000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.97     |\n",
      "|    critic_loss     | 0.226    |\n",
      "|    ent_coef        | 0.000364 |\n",
      "|    ent_coef_loss   | -7.5     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 139899   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    episodes        | 140    |\n",
      "|    fps             | 3      |\n",
      "|    time_elapsed    | 38552  |\n",
      "|    total_timesteps | 140000 |\n",
      "-------------------------------\n",
      "Track generation: 1202..1515 -> 313-tiles track\n",
      "Track generation: 1231..1543 -> 312-tiles track\n",
      "Track generation: 959..1210 -> 251-tiles track\n",
      "Track generation: 1161..1455 -> 294-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 39665    |\n",
      "|    total_timesteps | 144000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.519    |\n",
      "|    critic_loss     | 0.088    |\n",
      "|    ent_coef        | 0.00065  |\n",
      "|    ent_coef_loss   | 4.65     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 143899   |\n",
      "---------------------------------\n",
      "Track generation: 1239..1553 -> 314-tiles track\n",
      "Track generation: 1164..1459 -> 295-tiles track\n",
      "Track generation: 1092..1369 -> 277-tiles track\n",
      "Track generation: 1243..1558 -> 315-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 40779    |\n",
      "|    total_timesteps | 148000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.16     |\n",
      "|    critic_loss     | 0.0331   |\n",
      "|    ent_coef        | 0.000671 |\n",
      "|    ent_coef_loss   | -11.6    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 147899   |\n",
      "---------------------------------\n",
      "Track generation: 1175..1473 -> 298-tiles track\n",
      "Track generation: 1146..1437 -> 291-tiles track\n",
      "Track generation: 1040..1304 -> 264-tiles track\n",
      "Track generation: 1220..1529 -> 309-tiles track\n",
      "Track generation: 1184..1484 -> 300-tiles track\n",
      "Track generation: 1243..1558 -> 315-tiles track\n",
      "Track generation: 1119..1403 -> 284-tiles track\n",
      "Track generation: 1136..1424 -> 288-tiles track\n",
      "Eval num_timesteps=150000, episode_reward=-82.89 +/- 1.12\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -82.9    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 150000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.07     |\n",
      "|    critic_loss     | 0.155    |\n",
      "|    ent_coef        | 0.000758 |\n",
      "|    ent_coef_loss   | 10.9     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 149899   |\n",
      "---------------------------------\n",
      "Track generation: 1039..1304 -> 265-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1244..1559 -> 315-tiles track\n",
      "Track generation: 1176..1474 -> 298-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 41910    |\n",
      "|    total_timesteps | 152000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.72     |\n",
      "|    critic_loss     | 0.0967   |\n",
      "|    ent_coef        | 0.000677 |\n",
      "|    ent_coef_loss   | 21       |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 151899   |\n",
      "---------------------------------\n",
      "Track generation: 1252..1569 -> 317-tiles track\n",
      "Track generation: 1103..1387 -> 284-tiles track\n",
      "Track generation: 1321..1655 -> 334-tiles track\n",
      "Track generation: 1108..1389 -> 281-tiles track\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 43008    |\n",
      "|    total_timesteps | 156000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.12     |\n",
      "|    critic_loss     | 0.255    |\n",
      "|    ent_coef        | 0.000496 |\n",
      "|    ent_coef_loss   | 7.23     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 155899   |\n",
      "---------------------------------\n",
      "Track generation: 1291..1618 -> 327-tiles track\n",
      "Track generation: 1099..1378 -> 279-tiles track\n",
      "Track generation: 1074..1349 -> 275-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1106..1385 -> 279-tiles track\n",
      "Track generation: 1257..1584 -> 327-tiles track\n",
      "Track generation: 1212..1519 -> 307-tiles track\n",
      "Track generation: 1091..1368 -> 277-tiles track\n",
      "Track generation: 1182..1491 -> 309-tiles track\n",
      "Track generation: 1150..1442 -> 292-tiles track\n",
      "Track generation: 929..1168 -> 239-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1024..1284 -> 260-tiles track\n",
      "Track generation: 1129..1415 -> 286-tiles track\n",
      "Eval num_timesteps=160000, episode_reward=-83.21 +/- 2.14\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -83.2    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 160000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.52     |\n",
      "|    critic_loss     | 0.101    |\n",
      "|    ent_coef        | 0.000572 |\n",
      "|    ent_coef_loss   | -3.41    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 159899   |\n",
      "---------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    episodes        | 160    |\n",
      "|    fps             | 3      |\n",
      "|    time_elapsed    | 44121  |\n",
      "|    total_timesteps | 160000 |\n",
      "-------------------------------\n",
      "Track generation: 1237..1550 -> 313-tiles track\n",
      "Track generation: 1103..1383 -> 280-tiles track\n",
      "Track generation: 1212..1519 -> 307-tiles track\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5016\\3841760041.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m350000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_callback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\stable_baselines3\\sac\\sac.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    290\u001b[0m     ) -> OffPolicyAlgorithm:\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         return super(SAC, self).learn(\n\u001b[0m\u001b[0;32m    293\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    364\u001b[0m                 \u001b[1;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\stable_baselines3\\sac\\sac.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[1;31m# Alternative: actor_loss = th.mean(log_prob - qf1_pi)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[1;31m# Mean over all critic networks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mq_values_pi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions_pi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m             \u001b[0mmin_qf_pi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_values_pi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0mactor_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ment_coef\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin_qf_pi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, obs, actions)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;31m# when the features_extractor is shared with the actor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshare_features_extractor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m         \u001b[0mqvalue_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqvalue_input\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mq_net\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq_networks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No features extractor was set\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mpreprocessed_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_obs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_constructor_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, observations)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patryk\\Documents\\earin-labs\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    441\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 443\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    444\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=350000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_path = os.path.join('Training', 'Saved Models', 'SAC_CnnPolicy_Driving_model_350k') # saves the last, not the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(ppo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1167..1463 -> 296-tiles track\n",
      "Track generation: 1134..1400 -> 266-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1327..1662 -> 335-tiles track\n",
      "Track generation: 1045..1310 -> 265-tiles track\n",
      "Track generation: 1141..1430 -> 289-tiles track\n",
      "Track generation: 1009..1264 -> 255-tiles track\n",
      "Track generation: 1192..1494 -> 302-tiles track\n",
      "Track generation: 1261..1580 -> 319-tiles track\n",
      "Track generation: 1193..1496 -> 303-tiles track\n",
      "Track generation: 1071..1346 -> 275-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1155..1457 -> 302-tiles track\n",
      "Track generation: 1179..1478 -> 299-tiles track\n",
      "Track generation: 1313..1644 -> 331-tiles track\n",
      "Track generation: 1061..1336 -> 275-tiles track\n",
      "Track generation: 1141..1435 -> 294-tiles track\n",
      "Track generation: 1141..1430 -> 289-tiles track\n",
      "Track generation: 1135..1423 -> 288-tiles track\n",
      "Track generation: 1150..1451 -> 301-tiles track\n",
      "Track generation: 1066..1343 -> 277-tiles track\n",
      "Track generation: 1088..1371 -> 283-tiles track\n",
      "Track generation: 1107..1390 -> 283-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1209..1515 -> 306-tiles track\n",
      "Track generation: 1109..1395 -> 286-tiles track\n",
      "Track generation: 1194..1506 -> 312-tiles track\n",
      "(-93.16233967393637, 0.4478046791611687)\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_policy(model, env, n_eval_episodes=20, render=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = 0\n",
    "while True:\n",
    "    obs = env.reset()\n",
    "    score = 0 \n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs.copy())\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        score+=rewards\n",
    "        env.render()\n",
    "    episode += 1\n",
    "    print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "ppo_path = os.path.join('Training', 'Saved Models','the_best_ppo_cnn', 'best_model')\n",
    "model = PPO.load(ppo_path, env)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f75cfd8d83e5e0ff5efcf80446b358d1c19dbf94fee83ea009cf8f53d56b402f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
