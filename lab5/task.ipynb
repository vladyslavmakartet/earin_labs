{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # data processing, CSV file I/O\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "# make a plot outputs appear and be stored within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_NAMES = {\n",
    "    1: \"alif\",\n",
    "    10: \"ra\",\n",
    "    11: \"zay\",\n",
    "    12: \"sin\",\n",
    "    13: \"shin\",\n",
    "    14: \"sad\",\n",
    "    15: \"dad\",\n",
    "    16: \"da\",\n",
    "    17: \"za\",\n",
    "    18: \"ayn\",\n",
    "    19: \"gayn\",\n",
    "    2: \"ba\",\n",
    "    20: \"fa\",\n",
    "    21: \"qaf\",\n",
    "    22: \"kaf\",\n",
    "    23: \"lam\",\n",
    "    24: \"mim\",\n",
    "    25: \"non\",\n",
    "    26: \"ha\",\n",
    "    27: \"waw\",\n",
    "    28: \"ya\",\n",
    "    29: \"hamza\",\n",
    "    3: \"ta\",\n",
    "    4: \"tha\",\n",
    "    5: \"gim\",\n",
    "    6: \"ha\",\n",
    "    7: \"kha\",\n",
    "    8: \"dal\",\n",
    "    9: \"thal\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"./X_train.csv\")\n",
    "y_train = pd.read_csv(\"./y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n",
      "       'pixel7', 'pixel8', 'pixel9',\n",
      "       ...\n",
      "       'pixel1014', 'pixel1015', 'pixel1016', 'pixel1017', 'pixel1018',\n",
      "       'pixel1019', 'pixel1020', 'pixel1021', 'pixel1022', 'pixel1023'],\n",
      "      dtype='object', length=1024)\n",
      "Index(['label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(x_train.columns)\n",
    "print(y_train.columns)\n",
    "assert len(x_train) == len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37933 entries, 0 to 37932\n",
      "Columns: 1024 entries, pixel0 to pixel1023\n",
      "dtypes: int64(1024)\n",
      "memory usage: 296.4 MB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37933 entries, 0 to 37932\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   label   37933 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 296.5 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "y_train['label'].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([x_train[column].max() for column in x_train.columns] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each pixel takes value 0-255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing data format to compatible with tf training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(x_train.index)\n",
    "x_train = x_train.reindex(idx)\n",
    "y_train = y_train.reindex(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(37933, 1024), dtype=float64, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tf = tf.convert_to_tensor(x_train)\n",
    "x_train_tf = x_train_tf / 255 # normalisation from 0 - 255 to 0 - 1\n",
    "x_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33583</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35270</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21193</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26095</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18660</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21814</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33206</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37933 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "4675       2\n",
       "33583     25\n",
       "35270     27\n",
       "3294       1\n",
       "21193     16\n",
       "...      ...\n",
       "26095     19\n",
       "1497       0\n",
       "18660     14\n",
       "21814     16\n",
       "33206     25\n",
       "\n",
       "[37933 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tf = y_train - 1\n",
    "y_train_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data\n",
    "For assessing accuracy, loss, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv(\"./X_test.csv\")\n",
    "y_test = pd.read_csv(\"./y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9496</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9497</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9498</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9499</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9500</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9501 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "...     ...\n",
       "9496     28\n",
       "9497     28\n",
       "9498     28\n",
       "9499     28\n",
       "9500     28\n",
       "\n",
       "[9501 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tf = tf.convert_to_tensor(x_test)\n",
    "x_test_tf = x_test_tf / 255 # normalisation from 0 - 255 to 0 - 1\n",
    "y_test_tf = y_test - 1\n",
    "y_test_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\n",
    "NUMBER_OF_LAYERS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=1024))\n",
    "\n",
    "    for i in range(NUMBER_OF_LAYERS):\n",
    "        # Tune the number of units in the first Dense layer\n",
    "        # Choose an optimal value between 4-1024\n",
    "        hp_units = hp.Int(f'units_{i}', min_value=5, max_value=516, step=3)\n",
    "        model.add(tf.keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(29))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    project_name='hyperparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 36s]\n",
      "val_accuracy: 0.5079072117805481\n",
      "\n",
      "Best val_accuracy So Far: 0.542171835899353\n",
      "Total elapsed time: 01h 03m 15s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train_tf, y_train_tf, epochs=100, validation_split=0.1, shuffle=True, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.001\n",
      "Layer 0: 491\n",
      "Layer 1: 269\n",
      "Layer 2: 218\n",
      "Layer 3: 104\n",
      "Layer 4: 113\n",
      "Layer 5: 299\n"
     ]
    }
   ],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "print(f\"learning_rate: {best_hps.get('learning_rate')}\")\n",
    "for i in range(NUMBER_OF_LAYERS):\n",
    "    print(f\"Layer {i}: {best_hps.get(f'units_{i}')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1067/1067 [==============================] - 3s 3ms/step - loss: 2.6300 - accuracy: 0.2168 - val_loss: 2.2082 - val_accuracy: 0.3184\n",
      "Epoch 2/300\n",
      "1067/1067 [==============================] - 3s 3ms/step - loss: 1.9439 - accuracy: 0.3844 - val_loss: 1.9266 - val_accuracy: 0.3951\n",
      "Epoch 3/300\n",
      "1067/1067 [==============================] - 3s 3ms/step - loss: 1.5809 - accuracy: 0.4894 - val_loss: 1.7761 - val_accuracy: 0.4294\n",
      "Epoch 4/300\n",
      "1067/1067 [==============================] - 3s 3ms/step - loss: 1.3313 - accuracy: 0.5628 - val_loss: 1.7023 - val_accuracy: 0.4792\n",
      "Epoch 5/300\n",
      "1067/1067 [==============================] - 3s 3ms/step - loss: 1.1332 - accuracy: 0.6260 - val_loss: 1.6739 - val_accuracy: 0.5003\n",
      "Epoch 6/300\n",
      "1067/1067 [==============================] - 3s 3ms/step - loss: 0.9788 - accuracy: 0.6732 - val_loss: 1.7175 - val_accuracy: 0.4989\n",
      "Epoch 7/300\n",
      "1067/1067 [==============================] - 3s 3ms/step - loss: 0.8420 - accuracy: 0.7194 - val_loss: 1.7438 - val_accuracy: 0.5063\n",
      "Epoch 8/300\n",
      "1067/1067 [==============================] - 3s 3ms/step - loss: 0.7323 - accuracy: 0.7557 - val_loss: 1.7909 - val_accuracy: 0.5240\n",
      "Epoch 9/300\n",
      "1067/1067 [==============================] - 3s 3ms/step - loss: 0.6454 - accuracy: 0.7868 - val_loss: 1.8618 - val_accuracy: 0.5240\n",
      "Epoch 10/300\n",
      "1067/1067 [==============================] - 3s 3ms/step - loss: 0.5767 - accuracy: 0.8093 - val_loss: 1.9984 - val_accuracy: 0.5103\n",
      "Epoch 11/300\n",
      "1067/1067 [==============================] - 3s 3ms/step - loss: 0.5089 - accuracy: 0.8303 - val_loss: 2.0989 - val_accuracy: 0.5203\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_tf, y_train_tf, epochs=300, shuffle=True, validation_split=0.1, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 - 0s - loss: 2.0783 - accuracy: 0.5285 - 362ms/epoch - 1ms/step\n",
      "\n",
      "Test accuracy: 0.5284706950187683\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test_tf,  y_test_tf, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f75cfd8d83e5e0ff5efcf80446b358d1c19dbf94fee83ea009cf8f53d56b402f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
