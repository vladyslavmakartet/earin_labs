{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # data processing, CSV file I/O\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "# make a plot outputs appear and be stored within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_NAMES = {\n",
    "    1: \"alif\",\n",
    "    10: \"ra\",\n",
    "    11: \"zay\",\n",
    "    12: \"sin\",\n",
    "    13: \"shin\",\n",
    "    14: \"sad\",\n",
    "    15: \"dad\",\n",
    "    16: \"da\",\n",
    "    17: \"za\",\n",
    "    18: \"ayn\",\n",
    "    19: \"gayn\",\n",
    "    2: \"ba\",\n",
    "    20: \"fa\",\n",
    "    21: \"qaf\",\n",
    "    22: \"kaf\",\n",
    "    23: \"lam\",\n",
    "    24: \"mim\",\n",
    "    25: \"non\",\n",
    "    26: \"ha\",\n",
    "    27: \"waw\",\n",
    "    28: \"ya\",\n",
    "    29: \"hamza\",\n",
    "    3: \"ta\",\n",
    "    4: \"tha\",\n",
    "    5: \"gim\",\n",
    "    6: \"ha\",\n",
    "    7: \"kha\",\n",
    "    8: \"dal\",\n",
    "    9: \"thal\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"./X_train.csv\")\n",
    "y_train = pd.read_csv(\"./y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n",
      "       'pixel7', 'pixel8', 'pixel9',\n",
      "       ...\n",
      "       'pixel1014', 'pixel1015', 'pixel1016', 'pixel1017', 'pixel1018',\n",
      "       'pixel1019', 'pixel1020', 'pixel1021', 'pixel1022', 'pixel1023'],\n",
      "      dtype='object', length=1024)\n",
      "Index(['label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(x_train.columns)\n",
    "print(y_train.columns)\n",
    "assert len(x_train) == len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37933 entries, 0 to 37932\n",
      "Columns: 1024 entries, pixel0 to pixel1023\n",
      "dtypes: int64(1024)\n",
      "memory usage: 296.4 MB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37933 entries, 0 to 37932\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   label   37933 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 296.5 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "y_train['label'].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([x_train[column].max() for column in x_train.columns] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each pixel takes value 0-255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing data format to compatible with tf training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(37933, 1024), dtype=float64, numpy=\n",
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.01568627,\n",
       "        0.02352941],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.01176471, 0.04313725, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tf = tf.convert_to_tensor(x_train)\n",
    "x_train_tf = x_train_tf / 255 # normalisation from 0 - 255 to 0 - 1\n",
    "x_train_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data\n",
    "For assessing accuracy, loss, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv(\"./X_test.csv\")\n",
    "y_test = pd.read_csv(\"./y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9496</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9497</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9498</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9499</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9500</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9501 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "...     ...\n",
       "9496     28\n",
       "9497     28\n",
       "9498     28\n",
       "9499     28\n",
       "9500     28\n",
       "\n",
       "[9501 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tf = tf.convert_to_tensor(x_test)\n",
    "x_test_tf = x_test_tf / 255 # normalisation from 0 - 255 to 0 - 1\n",
    "y_test_tf = y_test - 1\n",
    "y_test_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37928</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37929</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37930</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37931</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37932</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37933 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "...      ...\n",
       "37928     28\n",
       "37929     28\n",
       "37930     28\n",
       "37931     28\n",
       "37932     28\n",
       "\n",
       "[37933 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tf = y_train - 1\n",
    "y_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best result\n",
    "256,50,50 51%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=1024))\n",
    "\n",
    "    layer_count = hp.Int('layers', min_value=2, max_value=10, step=1)\n",
    "    activation_functions= ['linear', 'relu', 'softmax', 'sigmoid']\n",
    "\n",
    "    for i in range(layer_count):\n",
    "        # Tune the number of units in the first Dense layer\n",
    "        # Choose an optimal value between 4-1024\n",
    "        hp_activations = hp.Choice(f'activation_function_{i}', values=activation_functions)\n",
    "        hp_units = hp.Int(f'units_{i}', min_value=4, max_value=1024, step=4)\n",
    "        model.add(tf.keras.layers.Dense(units=hp_units, activation=hp_activations))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(29))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    project_name='hyperparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 01m 01s]\n",
      "val_accuracy: 0.0\n",
      "\n",
      "Best val_accuracy So Far: 0.007249242160469294\n",
      "Total elapsed time: 00h 11m 19s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train_tf, y_train_tf, epochs=50, validation_split=0.2, shuffle=True, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 2.5894 - accuracy: 0.2181 - val_loss: 11.9923 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 2.0629 - accuracy: 0.3492 - val_loss: 13.7536 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 1.8024 - accuracy: 0.4291 - val_loss: 16.5887 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 1.6163 - accuracy: 0.4811 - val_loss: 18.9884 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 1.4791 - accuracy: 0.5184 - val_loss: 18.3906 - val_accuracy: 1.3180e-04\n",
      "Epoch 6/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 1.3803 - accuracy: 0.5473 - val_loss: 22.2550 - val_accuracy: 2.6361e-04\n",
      "Epoch 7/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 1.3002 - accuracy: 0.5755 - val_loss: 23.4438 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 1.2392 - accuracy: 0.5976 - val_loss: 24.5728 - val_accuracy: 1.3180e-04\n",
      "Epoch 9/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 1.1678 - accuracy: 0.6162 - val_loss: 26.1768 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 1.1175 - accuracy: 0.6325 - val_loss: 29.7939 - val_accuracy: 1.3180e-04\n",
      "Epoch 11/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 1.0716 - accuracy: 0.6462 - val_loss: 28.5825 - val_accuracy: 7.9083e-04\n",
      "Epoch 12/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 1.0312 - accuracy: 0.6575 - val_loss: 33.1058 - val_accuracy: 0.0013\n",
      "Epoch 13/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.9797 - accuracy: 0.6767 - val_loss: 37.4958 - val_accuracy: 1.3180e-04\n",
      "Epoch 14/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.9506 - accuracy: 0.6832 - val_loss: 40.4536 - val_accuracy: 0.0020\n",
      "Epoch 15/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.9122 - accuracy: 0.6987 - val_loss: 41.5933 - val_accuracy: 2.6361e-04\n",
      "Epoch 16/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.8782 - accuracy: 0.7096 - val_loss: 44.2202 - val_accuracy: 0.0022\n",
      "Epoch 17/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.8544 - accuracy: 0.7168 - val_loss: 42.8449 - val_accuracy: 0.0024\n",
      "Epoch 18/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.8180 - accuracy: 0.7285 - val_loss: 49.0441 - val_accuracy: 7.9083e-04\n",
      "Epoch 19/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.7957 - accuracy: 0.7367 - val_loss: 50.6582 - val_accuracy: 6.5902e-04\n",
      "Epoch 20/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.7821 - accuracy: 0.7401 - val_loss: 55.3416 - val_accuracy: 0.0059\n",
      "Epoch 21/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.7482 - accuracy: 0.7542 - val_loss: 57.5945 - val_accuracy: 0.0050\n",
      "Epoch 22/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.7304 - accuracy: 0.7561 - val_loss: 58.8265 - val_accuracy: 0.0029\n",
      "Epoch 23/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.7090 - accuracy: 0.7662 - val_loss: 57.0041 - val_accuracy: 0.0017\n",
      "Epoch 24/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.6852 - accuracy: 0.7750 - val_loss: 58.7295 - val_accuracy: 0.0040\n",
      "Epoch 25/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.6799 - accuracy: 0.7803 - val_loss: 63.5188 - val_accuracy: 0.0038\n",
      "Epoch 26/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.6517 - accuracy: 0.7861 - val_loss: 67.1919 - val_accuracy: 0.0038\n",
      "Epoch 27/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.6307 - accuracy: 0.7911 - val_loss: 71.3854 - val_accuracy: 0.0040\n",
      "Epoch 28/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.6078 - accuracy: 0.7993 - val_loss: 70.1427 - val_accuracy: 0.0041\n",
      "Epoch 29/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.6154 - accuracy: 0.8020 - val_loss: 73.3286 - val_accuracy: 0.0065\n",
      "Epoch 30/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.5996 - accuracy: 0.8076 - val_loss: 71.6146 - val_accuracy: 0.0075\n",
      "Epoch 31/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.5661 - accuracy: 0.8167 - val_loss: 77.3097 - val_accuracy: 0.0050\n",
      "Epoch 32/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.5779 - accuracy: 0.8128 - val_loss: 86.1677 - val_accuracy: 0.0038\n",
      "Epoch 33/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.5497 - accuracy: 0.8218 - val_loss: 79.1230 - val_accuracy: 0.0021\n",
      "Epoch 34/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.5336 - accuracy: 0.8290 - val_loss: 85.9165 - val_accuracy: 0.0041\n",
      "Epoch 35/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.5288 - accuracy: 0.8304 - val_loss: 84.5460 - val_accuracy: 0.0070\n",
      "Epoch 36/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.5203 - accuracy: 0.8336 - val_loss: 90.3203 - val_accuracy: 0.0017\n",
      "Epoch 37/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.5174 - accuracy: 0.8340 - val_loss: 79.3245 - val_accuracy: 0.0112\n",
      "Epoch 38/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.5078 - accuracy: 0.8369 - val_loss: 90.7652 - val_accuracy: 0.0047\n",
      "Epoch 39/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4978 - accuracy: 0.8412 - val_loss: 93.3743 - val_accuracy: 0.0104\n",
      "Epoch 40/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4903 - accuracy: 0.8454 - val_loss: 92.4032 - val_accuracy: 0.0065\n",
      "Epoch 41/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4806 - accuracy: 0.8471 - val_loss: 98.2538 - val_accuracy: 0.0069\n",
      "Epoch 42/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4626 - accuracy: 0.8535 - val_loss: 95.9602 - val_accuracy: 0.0042\n",
      "Epoch 43/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4789 - accuracy: 0.8505 - val_loss: 93.2039 - val_accuracy: 0.0041\n",
      "Epoch 44/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4348 - accuracy: 0.8636 - val_loss: 104.0050 - val_accuracy: 0.0065\n",
      "Epoch 45/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4383 - accuracy: 0.8623 - val_loss: 94.3406 - val_accuracy: 0.0150\n",
      "Epoch 46/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4427 - accuracy: 0.8631 - val_loss: 100.9491 - val_accuracy: 0.0130\n",
      "Epoch 47/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4288 - accuracy: 0.8693 - val_loss: 101.5096 - val_accuracy: 0.0066\n",
      "Epoch 48/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4378 - accuracy: 0.8649 - val_loss: 103.0341 - val_accuracy: 0.0049\n",
      "Epoch 49/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4346 - accuracy: 0.8679 - val_loss: 123.0171 - val_accuracy: 0.0045\n",
      "Epoch 50/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4232 - accuracy: 0.8711 - val_loss: 114.4233 - val_accuracy: 0.0086\n",
      "Epoch 51/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4157 - accuracy: 0.8727 - val_loss: 117.5771 - val_accuracy: 0.0219\n",
      "Epoch 52/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4156 - accuracy: 0.8756 - val_loss: 114.5422 - val_accuracy: 0.0025\n",
      "Epoch 53/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.3913 - accuracy: 0.8802 - val_loss: 120.6712 - val_accuracy: 0.0087\n",
      "Epoch 54/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.4341 - accuracy: 0.8719 - val_loss: 115.6873 - val_accuracy: 0.0071\n",
      "Epoch 55/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.3737 - accuracy: 0.8865 - val_loss: 118.6044 - val_accuracy: 0.0082\n",
      "Epoch 56/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4022 - accuracy: 0.8798 - val_loss: 130.9946 - val_accuracy: 0.0066\n",
      "Epoch 57/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.3746 - accuracy: 0.8868 - val_loss: 123.6095 - val_accuracy: 0.0047\n",
      "Epoch 58/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.3905 - accuracy: 0.8832 - val_loss: 130.0372 - val_accuracy: 0.0055\n",
      "Epoch 59/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.4096 - accuracy: 0.8816 - val_loss: 138.0885 - val_accuracy: 0.0075\n",
      "Epoch 60/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.3697 - accuracy: 0.8913 - val_loss: 130.2388 - val_accuracy: 0.0062\n",
      "Epoch 61/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.3783 - accuracy: 0.8870 - val_loss: 138.8722 - val_accuracy: 0.0069\n",
      "Epoch 62/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.3673 - accuracy: 0.8950 - val_loss: 134.7195 - val_accuracy: 0.0095\n",
      "Epoch 63/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.3261 - accuracy: 0.9053 - val_loss: 128.5025 - val_accuracy: 0.0232\n",
      "Epoch 64/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.3541 - accuracy: 0.8986 - val_loss: 129.8970 - val_accuracy: 0.0095\n",
      "Epoch 65/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.4053 - accuracy: 0.8835 - val_loss: 145.9670 - val_accuracy: 0.0094\n",
      "Epoch 66/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.3475 - accuracy: 0.8993 - val_loss: 147.3725 - val_accuracy: 0.0061\n",
      "Epoch 67/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.3720 - accuracy: 0.8937 - val_loss: 144.0673 - val_accuracy: 0.0043\n",
      "Epoch 68/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.3411 - accuracy: 0.9012 - val_loss: 155.1171 - val_accuracy: 0.0058\n",
      "Epoch 69/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.3418 - accuracy: 0.9018 - val_loss: 146.0355 - val_accuracy: 0.0113\n",
      "Epoch 70/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.3404 - accuracy: 0.9042 - val_loss: 124.8391 - val_accuracy: 0.0078\n",
      "Epoch 71/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.3564 - accuracy: 0.8964 - val_loss: 155.5815 - val_accuracy: 0.0088\n",
      "Epoch 72/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.2950 - accuracy: 0.9142 - val_loss: 142.4135 - val_accuracy: 0.0045\n",
      "Epoch 73/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.3719 - accuracy: 0.8972 - val_loss: 151.7067 - val_accuracy: 0.0136\n",
      "Epoch 74/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.3659 - accuracy: 0.8988 - val_loss: 148.1500 - val_accuracy: 0.0055\n",
      "Epoch 75/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.2981 - accuracy: 0.9169 - val_loss: 137.6388 - val_accuracy: 0.0058\n",
      "Epoch 76/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.3163 - accuracy: 0.9112 - val_loss: 171.8636 - val_accuracy: 0.0076\n",
      "Epoch 77/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.3342 - accuracy: 0.9061 - val_loss: 150.4065 - val_accuracy: 0.0133\n",
      "Epoch 78/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.3540 - accuracy: 0.9038 - val_loss: 160.3821 - val_accuracy: 0.0045\n",
      "Epoch 79/300\n",
      "949/949 [==============================] - 6s 6ms/step - loss: 0.3465 - accuracy: 0.9086 - val_loss: 148.0249 - val_accuracy: 0.0017\n",
      "Epoch 80/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.3238 - accuracy: 0.9113 - val_loss: 155.9550 - val_accuracy: 0.0063\n",
      "Epoch 81/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.2981 - accuracy: 0.9186 - val_loss: 169.4681 - val_accuracy: 0.0107\n",
      "Epoch 82/300\n",
      "949/949 [==============================] - 6s 7ms/step - loss: 0.3198 - accuracy: 0.9140 - val_loss: 176.1031 - val_accuracy: 0.0045\n",
      "Epoch 83/300\n",
      "949/949 [==============================] - 7s 7ms/step - loss: 0.2970 - accuracy: 0.9182 - val_loss: 175.7018 - val_accuracy: 0.0075\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_tf, y_train_tf, epochs=300, callbacks=[stop_early], validation_split=0.2, shuffle=True, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 - 1s - loss: 37.1470 - accuracy: 0.4406 - 691ms/epoch - 2ms/step\n",
      "\n",
      "Test accuracy: 0.440585196018219\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test_tf,  y_test_tf, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f75cfd8d83e5e0ff5efcf80446b358d1c19dbf94fee83ea009cf8f53d56b402f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
