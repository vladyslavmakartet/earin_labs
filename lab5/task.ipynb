{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # data processing, CSV file I/O\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "# make a plot outputs appear and be stored within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTER_NAMES = {\n",
    "    1: \"alif\",\n",
    "    10: \"ra\",\n",
    "    11: \"zay\",\n",
    "    12: \"sin\",\n",
    "    13: \"shin\",\n",
    "    14: \"sad\",\n",
    "    15: \"dad\",\n",
    "    16: \"da\",\n",
    "    17: \"za\",\n",
    "    18: \"ayn\",\n",
    "    19: \"gayn\",\n",
    "    2: \"ba\",\n",
    "    20: \"fa\",\n",
    "    21: \"qaf\",\n",
    "    22: \"kaf\",\n",
    "    23: \"lam\",\n",
    "    24: \"mim\",\n",
    "    25: \"non\",\n",
    "    26: \"ha\",\n",
    "    27: \"waw\",\n",
    "    28: \"ya\",\n",
    "    29: \"hamza\",\n",
    "    3: \"ta\",\n",
    "    4: \"tha\",\n",
    "    5: \"gim\",\n",
    "    6: \"ha\",\n",
    "    7: \"kha\",\n",
    "    8: \"dal\",\n",
    "    9: \"thal\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"./X_train.csv\")\n",
    "y_train = pd.read_csv(\"./y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n",
      "       'pixel7', 'pixel8', 'pixel9',\n",
      "       ...\n",
      "       'pixel1014', 'pixel1015', 'pixel1016', 'pixel1017', 'pixel1018',\n",
      "       'pixel1019', 'pixel1020', 'pixel1021', 'pixel1022', 'pixel1023'],\n",
      "      dtype='object', length=1024)\n",
      "Index(['label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(x_train.columns)\n",
    "print(y_train.columns)\n",
    "assert len(x_train) == len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37933 entries, 0 to 37932\n",
      "Columns: 1024 entries, pixel0 to pixel1023\n",
      "dtypes: int64(1024)\n",
      "memory usage: 296.4 MB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37933 entries, 0 to 37932\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   label   37933 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 296.5 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "y_train['label'].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([x_train[column].max() for column in x_train.columns] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each pixel takes value 0-255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing data format to compatible with tf training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(x_train.index)\n",
    "x_train = x_train.reindex(idx)\n",
    "y_train = y_train.reindex(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(x_data):\n",
    "    rows_num = len(x_data)\n",
    "    new_shape = [rows_num, 32, 32, 1]\n",
    "    print(new_shape)\n",
    "    x_data_tf = x_data.values.reshape(new_shape)\n",
    "    x_data_tf = tf.convert_to_tensor(x_data_tf)\n",
    "    x_data_tf = x_data_tf / 255 # normalisation from 0 - 255 to 0 - 1\n",
    "    return x_data_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37933, 32, 32, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(37933, 32, 32, 1), dtype=float64, numpy=\n",
       "array([[[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.00392157],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.01568627],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.05490196],\n",
       "         [0.01568627],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.00392157],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00392157],\n",
       "         [0.00392157],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.00784314],\n",
       "         [0.00784314],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]],\n",
       "\n",
       "        [[0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         ...,\n",
       "         [0.        ],\n",
       "         [0.        ],\n",
       "         [0.        ]]]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tf = convert_to_tensor(x_train)\n",
    "x_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10853</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31723</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24341</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17526</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28152</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21502</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6244</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15903</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8100</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37933 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "10853      6\n",
       "31723     24\n",
       "24341     18\n",
       "5298       3\n",
       "17526     13\n",
       "...      ...\n",
       "28152     21\n",
       "21502     16\n",
       "6244       3\n",
       "15903     12\n",
       "8100       5\n",
       "\n",
       "[37933 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tf = y_train - 1\n",
    "y_train_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data\n",
    "For assessing accuracy, loss, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv(\"./X_test.csv\")\n",
    "y_test = pd.read_csv(\"./y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9501, 32, 32, 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9496</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9497</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9498</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9499</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9500</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9501 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "...     ...\n",
       "9496     28\n",
       "9497     28\n",
       "9498     28\n",
       "9499     28\n",
       "9500     28\n",
       "\n",
       "[9501 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tf = convert_to_tensor(x_test)\n",
    "y_test_tf = y_test - 1\n",
    "y_test_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\n",
    "NUMBER_OF_LAYERS = 7\n",
    "NUMBER_OF_CONV2D = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(32, 32, 1)))\n",
    "    for i in range(NUMBER_OF_CONV2D):\n",
    "        model.add(tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "    model.add(tf.keras.layers.Reshape((16,1)))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences=True)))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, return_sequences=True)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    for i in range(NUMBER_OF_LAYERS):\n",
    "        # Tune the number of units in the first Dense layer\n",
    "        # Choose an optimal value between 4-1024\n",
    "        hp_units = hp.Int(f'units_{i}', min_value=5, max_value=516, step=3)\n",
    "        model.add(tf.keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(29))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\hyperparams\\oracle.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    project_name='hyperparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 14m 51s]\n",
      "val_accuracy: 0.7907221913337708\n",
      "\n",
      "Best val_accuracy So Far: 0.8046916127204895\n",
      "Total elapsed time: 04h 45m 03s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train_tf, y_train_tf, epochs=50, validation_split=0.1, shuffle=True, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.001\n",
      "Layer 0: 281\n",
      "Layer 1: 89\n",
      "Layer 2: 401\n",
      "Layer 3: 296\n",
      "Layer 4: 263\n",
      "Layer 5: 80\n",
      "Layer 6: 362\n"
     ]
    }
   ],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "print(f\"learning_rate: {best_hps.get('learning_rate')}\")\n",
    "for i in range(NUMBER_OF_LAYERS):\n",
    "    print(f\"Layer {i}: {best_hps.get(f'units_{i}')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1067/1067 [==============================] - 28s 23ms/step - loss: 3.0178 - accuracy: 0.1040 - val_loss: 2.7696 - val_accuracy: 0.1405\n",
      "Epoch 2/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 2.5149 - accuracy: 0.1922 - val_loss: 2.3721 - val_accuracy: 0.2148\n",
      "Epoch 3/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 2.0935 - accuracy: 0.2986 - val_loss: 1.8797 - val_accuracy: 0.3614\n",
      "Epoch 4/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 1.7145 - accuracy: 0.4150 - val_loss: 1.5696 - val_accuracy: 0.4755\n",
      "Epoch 5/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 1.4207 - accuracy: 0.5210 - val_loss: 1.3179 - val_accuracy: 0.5669\n",
      "Epoch 6/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 1.2430 - accuracy: 0.5845 - val_loss: 1.2072 - val_accuracy: 0.5941\n",
      "Epoch 7/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 1.1243 - accuracy: 0.6276 - val_loss: 1.0788 - val_accuracy: 0.6476\n",
      "Epoch 8/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 1.0341 - accuracy: 0.6610 - val_loss: 1.1389 - val_accuracy: 0.6365\n",
      "Epoch 9/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.9585 - accuracy: 0.6872 - val_loss: 1.0748 - val_accuracy: 0.6584\n",
      "Epoch 10/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.9209 - accuracy: 0.7004 - val_loss: 0.9206 - val_accuracy: 0.7056\n",
      "Epoch 11/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.8809 - accuracy: 0.7152 - val_loss: 0.9071 - val_accuracy: 0.7111\n",
      "Epoch 12/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.8485 - accuracy: 0.7281 - val_loss: 0.9368 - val_accuracy: 0.7016\n",
      "Epoch 13/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.8231 - accuracy: 0.7394 - val_loss: 0.8647 - val_accuracy: 0.7312\n",
      "Epoch 14/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.7849 - accuracy: 0.7487 - val_loss: 0.8866 - val_accuracy: 0.7203\n",
      "Epoch 15/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.7592 - accuracy: 0.7585 - val_loss: 1.0693 - val_accuracy: 0.6813\n",
      "Epoch 16/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.7393 - accuracy: 0.7641 - val_loss: 0.8809 - val_accuracy: 0.7232\n",
      "Epoch 17/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.7277 - accuracy: 0.7690 - val_loss: 0.8763 - val_accuracy: 0.7309\n",
      "Epoch 18/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.6967 - accuracy: 0.7783 - val_loss: 0.8070 - val_accuracy: 0.7528\n",
      "Epoch 19/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.6845 - accuracy: 0.7852 - val_loss: 0.8518 - val_accuracy: 0.7404\n",
      "Epoch 20/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.6737 - accuracy: 0.7877 - val_loss: 0.8525 - val_accuracy: 0.7435\n",
      "Epoch 21/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.6577 - accuracy: 0.7908 - val_loss: 0.8214 - val_accuracy: 0.7472\n",
      "Epoch 22/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.6429 - accuracy: 0.7952 - val_loss: 0.7933 - val_accuracy: 0.7644\n",
      "Epoch 23/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.6253 - accuracy: 0.8027 - val_loss: 0.8090 - val_accuracy: 0.7570\n",
      "Epoch 24/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.6138 - accuracy: 0.8040 - val_loss: 0.8949 - val_accuracy: 0.7438\n",
      "Epoch 25/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.6002 - accuracy: 0.8098 - val_loss: 0.8141 - val_accuracy: 0.7604\n",
      "Epoch 26/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.5898 - accuracy: 0.8117 - val_loss: 0.9162 - val_accuracy: 0.7283\n",
      "Epoch 27/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.5744 - accuracy: 0.8170 - val_loss: 0.7794 - val_accuracy: 0.7723\n",
      "Epoch 28/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.5685 - accuracy: 0.8220 - val_loss: 0.7715 - val_accuracy: 0.7667\n",
      "Epoch 29/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.5581 - accuracy: 0.8244 - val_loss: 0.8870 - val_accuracy: 0.7412\n",
      "Epoch 30/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.5501 - accuracy: 0.8258 - val_loss: 0.8142 - val_accuracy: 0.7559\n",
      "Epoch 31/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.5391 - accuracy: 0.8269 - val_loss: 0.7766 - val_accuracy: 0.7715\n",
      "Epoch 32/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.5268 - accuracy: 0.8332 - val_loss: 0.8240 - val_accuracy: 0.7591\n",
      "Epoch 33/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.5213 - accuracy: 0.8339 - val_loss: 0.7983 - val_accuracy: 0.7712\n",
      "Epoch 34/300\n",
      "1067/1067 [==============================] - 24s 22ms/step - loss: 0.5202 - accuracy: 0.8346 - val_loss: 0.8116 - val_accuracy: 0.7820\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_tf, y_train_tf, epochs=300, shuffle=True, validation_split=0.1, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 16, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 8, 8, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 16)          2320      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 4, 4, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 16)          2320      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 2, 2, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 2, 2, 16)          2320      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 1, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 16, 1)             0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 16, 200)          81600     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 16, 100)          100400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 281)               449881    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 89)                25098     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 401)               36090     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 296)               118992    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 263)               78111     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 80)                21120     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 362)               29322     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 29)                10527     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 960,581\n",
      "Trainable params: 960,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 - 2s - loss: 0.8020 - accuracy: 0.7777 - 2s/epoch - 7ms/step\n",
      "\n",
      "Test accuracy: 0.7777076363563538\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test_tf,  y_test_tf, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f75cfd8d83e5e0ff5efcf80446b358d1c19dbf94fee83ea009cf8f53d56b402f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
